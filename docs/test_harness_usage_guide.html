<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>HEBench: Test Harness User Guide</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">HEBench
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('test_harness_usage_guide.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Test Harness User Guide </div>  </div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#autotoc_md178">Test Harness Usage Overview</a></li>
<li class="level1"><a href="#autotoc_md179">Test Harness Usage</a></li>
<li class="level1"><a href="#autotoc_md180">1. Test Harness Command Line Options</a></li>
<li class="level1"><a href="#autotoc_md181">2. Execute All Default Benchmarks for a Backend</a></li>
<li class="level1"><a href="#autotoc_md182">3. Configuring Benchmark Execution for a Backend</a><ul><li class="level2"><a href="#autotoc_md183">3.1 Running with a benchmark configuration file</a></li>
<li class="level2"><a href="#autotoc_md184">3.2 Exporting a benchmark configuration file</a></li>
<li class="level2"><a href="#autotoc_md185">3.3 Configuration file format</a></li>
</ul>
</li>
<li class="level1"><a href="#autotoc_md186">4. Output of Test Harness Run</a><ul><li class="level2"><a href="#autotoc_md187">4.1 Benchmark Reports</a></li>
</ul>
</li>
</ul>
</div>
<div class="textblock"><p><a class="anchor" id="md_docsrc_test_harness_usage_guide"></a></p>
<h1><a class="anchor" id="autotoc_md178"></a>
Test Harness Usage Overview</h1>
<p>This page describes and provides information on how to use the Test Harness application to configure and run workloads, output reports, dynamically load backends, and available command line options. For additional Test Harness information including how to extend it please refer to <a class="el" href="test_harness_overview.html">Test Harness Overview</a> .</p>
<h1><a class="anchor" id="autotoc_md179"></a>
Test Harness Usage</h1>
<p>The syntax for using Test Harness is shown below. It consists of calling the executable and a space separated list of options and arguments. The available options are listed in the options table on this page as well as available through test_harness help option.</p>
<div class="fragment"><div class="line">Usage:</div>
<div class="line">    ./test_harness OPTIONS</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md180"></a>
1. Test Harness Command Line Options</h1>
<p>To display the Test Harness help which lists all the available command line options, use the following command:</p>
<div class="fragment"><div class="line">./test_harness -h</div>
</div><!-- fragment --><h3>Backend selection and benchmark configuration options</h3>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone"><div style="width:390px">Option</div>   </th><th class="markdownTableHeadNone">Required   </th><th class="markdownTableHeadNone">Description    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>--backend_lib_path &lt;path_to_shared_lib&gt;</code> <br  />
 <code>--backend</code> <br  />
 <code>-b</code>   </td><td class="markdownTableBodyNone">Y   </td><td class="markdownTableBodyNone">Path to backend shared library. The library file must exist and be accessible for reading.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>--benchmark_config_file &lt;path_to_config_file&gt;</code> <br  />
 <code>--config_file</code> <br  />
<code>-c</code>   </td><td class="markdownTableBodyNone">N   </td><td class="markdownTableBodyNone">Path to benchmark run configuration file. YAML file specifying the selection of benchmarks and their workload parameters to run. If not present, all backend benchmarks will be run with default parameters.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>--dump_config</code> <br  />
 <code>--dump</code>   </td><td class="markdownTableBodyNone">N   </td><td class="markdownTableBodyNone">If specified, Test Harness will generate a general configuration file with the possible benchmarks that the backend can run. This file can be used as starting point template for a benchmark run configuration file. The destination file is specified by <code>--benchmark_config_file</code> argument. If this file already exists, it will be overwritten without warning. <br  />
 No actual benchmark is run. Application exits after the default configuration file is generated.   </td></tr>
</table>
<h3>Report options</h3>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone"><div style="width:390px">Option</div>   </th><th class="markdownTableHeadNone">Required   </th><th class="markdownTableHeadNone">Description    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>--compile_reports &lt;bool: 0;false;1;true&gt;</code> <br  />
 <code>--compile</code> <br  />
 <code>-C</code>   </td><td class="markdownTableBodyNone">N   </td><td class="markdownTableBodyNone">Enables (TRUE) or disables (FALSE) inline compilation of benchmark reports into summaries and statistics. Inline compilation is performed using default report compiler options. <br  />
 Extracting statistics may be time consuming, depending directly on the number of events recorded in each report. For benchmarks producing lengthy reports, or requiring specific report compiling options, users may opt to disable inline compilation and generate statistics and summaries using the report compiler later on the reports produced by the Test Harness run. <br  />
 Defaults to "TRUE".    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>--enable_validation &lt;bool: 0;false;1;true&gt;</code> <br  />
 <code>--validation</code>   </td><td class="markdownTableBodyNone">N   </td><td class="markdownTableBodyNone">Specifies whether results from benchmarks ran will be validated against ground truth. <br  />
 Defaults to "TRUE".    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>--report_delay &lt;delay_in_ms&gt;</code>   </td><td class="markdownTableBodyNone">N   </td><td class="markdownTableBodyNone">Delay between progress reports. Before each benchmark starts, Test Harness will pause for this specified number of milliseconds. Pass 0 to avoid delays. <br  />
 Defaults to 1000 ms.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>--report_root_path &lt;path_to_directory&gt;</code> <br  />
 <code>--output_dir</code>   </td><td class="markdownTableBodyNone">N   </td><td class="markdownTableBodyNone">Directory where to store the report output files. Directory must exist and be accessible for writing. A directory structure will be generated and any existing files with the same name will be overwritten. <br  />
 Defaults to current working directory "."    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>--run_overview &lt;bool: 0;false;1;true&gt;</code>   </td><td class="markdownTableBodyNone">N   </td><td class="markdownTableBodyNone">Specifies whether final summary overview of the benchmarks ran will be printed in standard output (TRUE) or not (FALSE). Results of the run will always be saved to storage regardless. <br  />
 Defaults to "TRUE".   </td></tr>
</table>
<h3>Global default</h3>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone"><div style="width:390px">Option</div>   </th><th class="markdownTableHeadNone">Required   </th><th class="markdownTableHeadNone">Description    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>--random_seed &lt;uint64&gt;</code> <br  />
 <code>--seed</code>   </td><td class="markdownTableBodyNone">N   </td><td class="markdownTableBodyNone">Specifies the random seed to use for pseudo-random number generation when none is specified by a benchmark configuration file. If no seed is specified, the current system clock time will be used as seed.   </td></tr>
</table>
<h3>Miscellaneous</h3>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone"><div style="width:390px">Option</div>   </th><th class="markdownTableHeadNone">Required   </th><th class="markdownTableHeadNone">Description    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>--version</code>   </td><td class="markdownTableBodyNone">N   </td><td class="markdownTableBodyNone">When present, outputs Test Harness version, required API Bridge version and currently linked API Bridge version. Application exits after this.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>-h, /h, \h, --help, /help, \help</code>   </td><td class="markdownTableBodyNone">N   </td><td class="markdownTableBodyNone">Shows this help. Application exits after this.   </td></tr>
</table>
<h1><a class="anchor" id="autotoc_md181"></a>
2. Execute All Default Benchmarks for a Backend</h1>
<p>A HEBench backend is a shared library (.so in Linux, .dll in Windows) that exposes the API Bridge functionality ( <a class="el" href="APIBridge_overview.html">API Bridge overview</a> ).</p>
<p>To run all of the tests with default parameters currently supported by a particular backend, call the test harness while also providing the name and location of the backend using the <code>--backend_lib_path</code> flag. In the example shown, we are calling test_harness for a backend as if it were located in the same path as test_harness. </p><div class="fragment"><div class="line">./test_harness --backend_lib_path libmy_backend.so</div>
</div><!-- fragment --><p> Optionally the output location for the performance report can also be specified. </p><div class="fragment"><div class="line">./test_harness --backend_lib_path libmy_backend.so --report_root_path ~/reports/</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md182"></a>
3. Configuring Benchmark Execution for a Backend</h1>
<h2><a class="anchor" id="autotoc_md183"></a>
3.1 Running with a benchmark configuration file</h2>
<p>Backends can support several workloads and offer a set of default parameters for each workload. Sometimes, however, we may want to run specific workloads, or workloads with parameters other than the default sets.</p>
<p>Test Harness offers facilities to configure the run using a configuration file. This benchmark configuration file is a YAML file that contains the list of which <em>benchmarks to run</em>, each <em>benchmark workload parameters</em>, and <em>external datasets</em> to use for each benchmark if desired.</p>
<p>If we already have a configuration file named <code>config.yaml</code>, we can load it for a Test Harness run as follows:</p>
<div class="fragment"><div class="line">./test_harness --backend_lib_path libmy_backend.so --benchmark_config_file config.yaml</div>
</div><!-- fragment --><p>This will launch the Test Harness which will load <code>config.yaml</code>, validate that the selection of benchmarks and parameters are supported by the backend, and then execute only those benchmarks specified in the configuration file.</p>
<h2><a class="anchor" id="autotoc_md184"></a>
3.2 Exporting a benchmark configuration file</h2>
<p>While the format of a benchmark configuration YAML file is standard for the Test Harness, the benchmark parameters and IDs may differ by backend. So, in order to find out the correct values for the configuration, a user may export the default benchmark configuration for a backend using the following:</p>
<div class="fragment"><div class="line">./test_harness --backend_lib_path libmy_backend.so --benchmark_config_file config.yaml --dump_config</div>
</div><!-- fragment --><p>This will launch the Test Harness which, instead of running any benchmarks, will query the specified backend and generate the file <code>config.yaml</code> containing the benchmark configuration information to run the backend with default parameters. This file will contain comments on how to use and which benchmark is represented by each section.</p>
<p>Exported default configuration files are the starting point for users to create their own run configuration by editing these files users to match their needs. Some workload parameter values may not be supported by certain backends, so, it is recommended to consult specific backend documentation for information on supported values.</p>
<h2><a class="anchor" id="autotoc_md185"></a>
3.3 Configuration file format</h2>
<p>For reference on the configuration file format, see <a class="el" href="config_file_reference.html">Benchmark Configuration File Reference</a> .</p>
<h1><a class="anchor" id="autotoc_md186"></a>
4. Output of Test Harness Run</h1>
<p>The output of a Test Harness run is dependent on the command line configuration.</p>
<p>The default behavior of Test Harness is to execute the benchmarks implemented in a backend specified with <code>--backend_lib_path</code> command line option. After completing a run, executing the benchmarks, Test Harness generates the files below, storing them in the location specified by <code>--report_root_path</code> command line option.</p>
<ul>
<li><b>report.csv</b>: for each benchmark executed, a CSV file containing detailed information of each event in the benchmark execution. Each report is formatted to be parsable by the report compiler. The actual location and filename for the report is dependent on the command line and the benchmark configurations.</li>
<li><b>benchmark_list.txt</b>: text file listing all report files generated; containing a filename per line. Each filename corresponds to the location of a report generated during the run. Each filename is either absolute, or relative to this file. This file is compatible with report compiler and can be used to compile the list of reports into statistics, summaries and overview of the run.</li>
</ul>
<p>If inline compilation is enabled (<code>--compile_reports</code> is "TRUE"), then, the corresponding report summaries, statistics and overview files are generated according to the report compiler operations. See <a class="el" href="report_compiler_overview.html">HEBench Report Compiler Overview</a> for more information.</p>
<h2><a class="anchor" id="autotoc_md187"></a>
4.1 Benchmark Reports</h2>
<p>All reports generated in a run are CSV files containing a header with information that describes the benchmark, followed by the report data based on whether the benchmark completed successfully, or failed.</p>
<h3>4.1.1 Successful Benchmarks</h3>
<p>Report file generated on a benchmark successful run contains every event recorded by Test Harness during execution. This file can be used with the <a class="el" href="report_compiler_overview.html">Report Compiler</a> to generate a summary file (CSV file in human friendly format) and a statistics CSV file containing statistical information extracted from the report.</p>
<h3>4.1.2 Failed Benchmarks</h3>
<p>Reports generated on failed benchmarks do not contain a list of events recorded. However, they contain information regarding the failure.</p>
<p>On recoverable failures, a message indicating the nature of the failure may appear in a section following the benchmark header.</p>
<p>If the failure was related to validation, Test Harness will output the operation input sample that caused the failure as well as the expected (correct) result and the result of the operation received from the backend. This behavior should help backend providers debug any problems during development or pinpoint issues with operation accuracy.</p>
<p>On unrecoverable (or critical) failures, no report is generated, and Test Harness execution is stopped. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1 </li>
  </ul>
</div>
</body>
</html>
