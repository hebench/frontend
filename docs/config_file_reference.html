<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>HEBench: Benchmark Configuration File Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">HEBench
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('config_file_reference.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Benchmark Configuration File Reference </div>  </div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#autotoc_md18">Configuration file syntax</a><ul><li class="level2"><a href="#autotoc_md19">Using Environment Variables as Values</a></li>
<li class="level2"><a href="#autotoc_md20">Configuration Scope</a></li>
<li class="level2"><a href="#autotoc_md21">Global Configuration Description</a></li>
<li class="level2"><a href="#autotoc_md22">Benchmark Configuration Section</a></li>
</ul>
</li>
<li class="level1"><a href="#autotoc_md23">Default benchmark configuration</a><ul><li class="level2"><a href="#autotoc_md24">Exporting default configuration</a></li>
<li class="level2"><a href="#autotoc_md25">Running with a configuration file</a></li>
</ul>
</li>
</ul>
</div>
<div class="textblock"><p><a class="anchor" id="md_docsrc_config_file_reference"></a></p>
<p>Benchmark configuration files can be specified during a run of Test Harness via the <code>--benchmark_config_file</code> command line argument.</p>
<p>A configuration file contains a list of benchmarks to run and parameters to use for each workload. While the syntax of configuration files is the same for all, IDs for benchmarks are specific to each backend.</p>
<h1><a class="anchor" id="autotoc_md18"></a>
Configuration file syntax</h1>
<p>A configuration file is a YAML file with the following syntax:</p>
<div class="fragment"><div class="line">default_min_test_time: &lt;fallback_min_test_time_ms&gt;</div>
<div class="line">default_sample_size: &lt;fallback_sample_size&gt;</div>
<div class="line">random_seed: &lt;seed&gt;</div>
<div class="line">initialization_data: &lt;data&gt;</div>
<div class="line"> </div>
<div class="line">benchmark:</div>
<div class="line">  - ID: &lt;benchmark_id&gt;</div>
<div class="line">    description:</div>
<div class="line">      workload_id: &lt;workload_id&gt;</div>
<div class="line">      workload_name: &lt;name&gt;</div>
<div class="line">      data_type: &lt;type_name&gt;</div>
<div class="line">      category: &lt;category_name&gt;</div>
<div class="line">      scheme: &lt;scheme_name&gt;</div>
<div class="line">      security: &lt;security_name&gt;</div>
<div class="line">      cipher_flags: &lt;ciphertext/plaintext_op_params&gt;</div>
<div class="line">      other: &lt;descriptor_extra_flags&gt;</div>
<div class="line">      notes: &lt;benchmark_notes&gt;</div>
<div class="line">    dataset: &lt;file_name&gt;</div>
<div class="line">    default_min_test_time: &lt;min_test_time_ms&gt;</div>
<div class="line">    default_sample_sizes:</div>
<div class="line">      0: &lt;sample_size&gt;</div>
<div class="line">      1: &lt;sample_size&gt;</div>
<div class="line">      ...</div>
<div class="line">    params:</div>
<div class="line">      0:</div>
<div class="line">        name: &lt;param_name&gt;</div>
<div class="line">        type: &lt;param_type&gt;</div>
<div class="line">        value:</div>
<div class="line">          from: &lt;value_from&gt;</div>
<div class="line">          to: &lt;value_to&gt;</div>
<div class="line">          step: &lt;value_step&gt;</div>
<div class="line">      1:</div>
<div class="line">        name: &lt;param_name&gt;</div>
<div class="line">        type: &lt;param_type&gt;</div>
<div class="line">        value:</div>
<div class="line">          from: &lt;value_from&gt;</div>
<div class="line">          to: &lt;value_to&gt;</div>
<div class="line">          step: &lt;value_step&gt;</div>
<div class="line">      ...</div>
<div class="line">  - ID: &lt;benchmark_id&gt;</div>
<div class="line">    description:</div>
<div class="line">      workload_id: &lt;workload_id&gt;</div>
<div class="line">      workload_name: &lt;name&gt;</div>
<div class="line">      data_type: &lt;type_name&gt;</div>
<div class="line">      category: &lt;category_name&gt;</div>
<div class="line">      scheme: &lt;scheme_name&gt;</div>
<div class="line">      security: &lt;security_name&gt;</div>
<div class="line">      cipher_flags: &lt;ciphertext/plaintext_op_params&gt;</div>
<div class="line">      other: &lt;descriptor_extra_flags&gt;</div>
<div class="line">      notes: &lt;benchmark_notes&gt;</div>
<div class="line">    dataset: &lt;file_name&gt;</div>
<div class="line">    default_min_test_time: &lt;min_test_time_ms&gt;</div>
<div class="line">    default_sample_sizes:</div>
<div class="line">      0: &lt;sample_size&gt;</div>
<div class="line">      1: &lt;sample_size&gt;</div>
<div class="line">      ...</div>
<div class="line">    params:</div>
<div class="line">      0:</div>
<div class="line">        name: &lt;param_name&gt;</div>
<div class="line">        type: &lt;param_type&gt;</div>
<div class="line">        value:</div>
<div class="line">          from: &lt;value_from&gt;</div>
<div class="line">          to: &lt;value_to&gt;</div>
<div class="line">          step: &lt;value_step&gt;</div>
<div class="line">      1:</div>
<div class="line">        name: &lt;param_name&gt;</div>
<div class="line">        type: &lt;param_type&gt;</div>
<div class="line">        value:</div>
<div class="line">          from: &lt;value_from&gt;</div>
<div class="line">          to: &lt;value_to&gt;</div>
<div class="line">          step: &lt;value_step&gt;</div>
<div class="line">      ...</div>
<div class="line">  ...</div>
</div><!-- fragment --><p><b>Note</b>: Nulls in YAML can be expressed with keyword <code>null</code> or <code>~</code> symbol.</p>
<h2><a class="anchor" id="autotoc_md19"></a>
Using Environment Variables as Values</h2>
<p>If the value of a key is of primitive type (numbers or strings), then, it can be specified locally by a literal in the configuration file, or externally, via environment variables.</p>
<p>The syntax for an environment variable is the <code>$</code> symbol followed by the name of the variable.</p>
<p>When loading the configuration file, Test Harness will substitute all environment variables used by the corresponding environment values (or empty string if the variable is not defined). Errors for incorrect values and types will be reported.</p>
<p>For example, the type of value <code>&lt;seed&gt;</code> for key <code>random_seed</code> is primitive type <code>uint64</code>, so, it can be specified locally with a literal as such:</p>
<div class="fragment"><div class="line">random_seed: 1234</div>
</div><!-- fragment --><p>or via an environment variable:</p>
<div class="fragment"><div class="line">random_seed: $RND_SEED</div>
</div><!-- fragment --><p>This should allow users to easily run several configurations without the need to modify their configuration files.</p>
<p><b>IMPORTANT</b>: Mixing environment variables with literals is not supported. A value must be an environment variable or a literal. The whole value will be considered the name of an environment variable if it starts with the <code>$</code> symbol.</p>
<p>For example, environment variables as part of a path will not be evaluated, unless the whole path is an environment variable.</p>
<div class="fragment"><div class="line">dataset: /tmp/$MY_FILE</div>
</div><!-- fragment --><p>In this case, the value for <code>dataset</code> will be set to <code>"/tmp/$MY_FILE"</code>.</p>
<p>However, if <code>MY_FILE=/tmp/data.csv</code> in the execution environment, then, the following...</p>
<div class="fragment"><div class="line">dataset: $MY_FILE</div>
</div><!-- fragment --><p>results in the value for <code>dataset</code> to be set to <code>"/tmp/data.csv"</code>.</p>
<h2><a class="anchor" id="autotoc_md20"></a>
Configuration Scope</h2>
<p>The actual value used for a benchmark configuration is based on where it is specified first in the priority list. The priority is:</p>
<ol type="1">
<li>Backend specified.</li>
<li>Benchmark description in configuration file.</li>
<li>Global in configuration file.</li>
<li><a class="el" href="tests_overview.html">Workload definition</a>.</li>
<li>Global execution specification (if any).</li>
</ol>
<p>This means, for example, if a benchmark description defines value <code>default_min_test_time: 10000</code>, this will override the configuration file global value for <code>default_min_test_time</code> (and any other value down the list).</p>
<p>If any of these is set to default or is missing, then the next down the list is used.</p>
<h2><a class="anchor" id="autotoc_md21"></a>
Global Configuration Description</h2>
<p>The configuration file can have settings for certain default behaviors. These are optional.</p>
<h3>Field default_min_test_time</h3>
<p><code>default_min_test_time</code> - type: <code>uint64</code>. Specifies the default minimum test time in <em>milliseconds</em> for a benchmark.</p>
<p>For <b>Latency</b> tests that support flexible test times, this is the minimum time for which they will run. As always, regardless of the value specified, all latency tests will run, at least, two iterations. <b>Offline</b> tests will run through the whole dataset, at least, once. If this minimum test time hasn't elapsed by the end of the run, a new run is executed. This behavior continues until the test time elapses.</p>
<p>If missing the global execution default is <code>0</code>.</p>
<h3>Field default_sample_size</h3>
<p><code>default_sample_size</code> - type: <code>uint64</code>. Specifies the number of samples to be used for an operation parameter in <b>Offline</b> tests that support flexible sample size. Inside the benchmark description, this setting specifies the sample size for an operand in the workload operation by index (missing indices, or values of <code>0</code> will cause the configuration to use this global configuration file value as a fallback).</p>
<p>A backend can directly specify the sample size for each operation parameter per benchmark for an Offline test using the <a class="el" href="namespacehebench_1_1APIBridge.html#structhebench_1_1APIBridge_1_1CategoryParams" title="Specifies parameters for a category.">hebench::APIBridge::CategoryParams</a> in the <a class="el" href="namespacehebench_1_1APIBridge.html#structhebench_1_1APIBridge_1_1BenchmarkDescriptor" title="Defines a benchmark test.">hebench::APIBridge::BenchmarkDescriptor</a> structure. If the backend sets the sample size for an operation parameter to <code>0</code>, it indicates that the parameter supports flexible sample sizes given through a configuration file via <code>default_sample_size</code>.</p>
<p>When this setting is missing or set to <code>0</code> in the configuration file, this indicates that the sample sizes pre-defined in the workload specification are to be used for parameters supporting flexible sample sizes. See <a class="el" href="tests_overview.html">HEBench Supported Workloads</a> for the specifications of all supported workloads.</p>
<h3>Field random_seed</h3>
<p><code>random_seed</code> - type: <code>uint64</code>. Specifies the seed for the random number generator to use when generating synthetic data. When missing, the global Test Harness seed will be used (see command line <code>--random_seed</code> in <a class="el" href="test_harness_usage_guide.html">Test Harness User Guide</a> ). This value can be used to replicate results during tests.</p>
<h3>Field initialization_data</h3>
<p><code>initialization_data</code> - type: <code>string</code>. (Optional field; can be <code>null</code>) Contains data to be passed to backend engine during initialization.</p>
<p>If the value of this field is an existing file name, Test Harness will read the file into memory as binary and pass the contents to the backend engine initialization through the call to <code><a class="el" href="namespacehebench_1_1APIBridge.html#aca77ce3aa9e8110ecc9668d746fa37ec" title="Initializes the backend engine.">initEngine()</a></code>. The file name can be relative to the configuration file, or absolute.</p>
<p>If this field does not contain a file name, Test Harness will just forward the specified string as is (no null terminator will be appended).</p>
<p>If this field is null, missing, or contains an empty string, Test Harness will pass <code>null</code> values for data to the engine initialization.</p>
<p>All data resulting from this field is kept in Test Harness memory during initialization as an array of bytes. Memory is freed and all pointers to the data become invalid after <code><a class="el" href="namespacehebench_1_1APIBridge.html#aca77ce3aa9e8110ecc9668d746fa37ec" title="Initializes the backend engine.">initEngine()</a></code> call returns.</p>
<h2><a class="anchor" id="autotoc_md22"></a>
Benchmark Configuration Section</h2>
<p>Top level <code>benchmark</code> key contains a list. This key must exist in the configuration file. An element of the value list specifies a benchmark to run and the corresponding configuration.</p>
<p>A benchmark configuration is composed by <code>ID</code>, <code>dataset</code>, <code>default_min_test_time</code>, <code>default_sample_sizes</code> and <code>params</code>.</p>
<p>The <code>description</code> section for each benchmark is automatically generated when exporting a configuration file for informational purposes only. It is intended to inform which is the benchmark descriptor matching the <code>benchmark ID</code>. Its contents are ignored by Test Harness, and thus, providing it is optional and may be omitted.</p>
<p>A benchmark executes a specific workload from the set of workloads specified in <a class="el" href="namespacehebench_1_1APIBridge.html#aeb7e1cd988a3ca98e5345d5bc90aa733" title="Defines all possible workloads.">hebench::APIBridge::Workload</a> enumeration. A backend implements a collection of benchmarks and registers them with the Frontend during initialization.</p>
<h3>Field ID</h3>
<p>The value of field <code>ID</code> is <code>&lt;benchmark_id&gt;</code>. This is an integer number identifying the benchmark to run. These IDs are backend specific that map to a registered benchmark. To obtain the correct ID, users can either find out by exporting the backend default configuration file, or, if available, in the backend documentation.</p>
<h3>Field dataset</h3>
<p>The <code>dataset</code> field is optional and <code>&lt;file_name&gt;</code> is a string specifying a file containing the input data and optional ground truths to use for the benchmark. If this field is a relative path, it is considered relative to the configuration file location. If this field is missing, or the value is <code>null</code>, Test Harness will attempt to pre-generate the data as specified in the benchmark's workload definition. Note that some workloads may not support pre-generating data, while others may not support external datasets. See <a class="el" href="tests_overview.html">HEBench Supported Workloads</a> for more information on each particular workload.</p>
<p>For formats supported by the Test Harness dataset loader see <a class="el" href="dataset_loader_overview.html">External Dataset Loader Overview</a> .</p>
<h3>Fields default_min_test_time and default_sample_sizes</h3>
<p>If <code>default_min_test_time</code>, or <code>default_sample_sizes</code> are specified, their values override those from the global configuration as per <b>Configuration Scope</b> above.</p>
<h3>Workload parameters</h3>
<p>Workloads executed by benchmarks have a number of mandatory parameters. The number and type for these parameters is workload specific. Required parameters for each workload are listed under the <a class="el" href="tests_overview.html">documentation for each workload</a>.</p>
<p>Arguments for the benchmark's workload parameters are specified under <code>params</code>. This is technically a list of parameters. Each argument is identified by its zero-based index. This index must correspond to the one in the workload documentation. Under its index, an argument specifies a <code>name</code>, a <code>type</code>, and a <code>value</code>.</p>
<p>The value of field <code>name</code> is <code>&lt;param_name&gt;</code>. This is any string used for description purposes. This string can be anything as long as it is unique inside the benchmark section. Names already populated by exported configuration files can be changed, but it is not recommended.</p>
<p>The value of field <code>type</code> is <code>&lt;param_type&gt;</code>. This is a string describing the type for the workload parameter. It is not case sensitive and must be one of:</p>
<ul>
<li><code>UInt64</code></li>
<li><code>Int64</code></li>
<li><code>Float64</code></li>
</ul>
<p>The correct type for each workload parameter is listed in the corresponding workload documentation. Types already populated by exported configuration files must not be changed as they already contain the correct value.</p>
<p>The <code>value</code> field specifies a range of values for this argument. The values of sub-fields <code>from</code>, <code>to</code> and <code>step</code> must be numbers compatible with the type specified by <code>&lt;param_type&gt;</code> in field <code>type</code>. Note that <code>&lt;value_to&gt;</code> must be greater than or equal to <code>&lt;value_from&gt;</code>.</p>
<p>A <code>&lt;value_step&gt;</code> of zero means that only <code>&lt;value_from&gt;</code> will be used in the range.</p>
<p>The range of values for the argument will run as follows:</p>
<div class="fragment"><div class="line"><span class="keywordflow">if</span> (value_step != 0)</div>
<div class="line">{</div>
<div class="line">    <span class="keywordflow">for</span> (value = value_from; value &lt;= value_to; value += value_step)</div>
<div class="line">    {</div>
<div class="line">        <span class="comment">// do something with value</span></div>
<div class="line">    }</div>
<div class="line">}</div>
<div class="line"><span class="keywordflow">else</span></div>
<div class="line">{</div>
<div class="line">    value = value_from;</div>
<div class="line">    <span class="comment">// do something with value</span></div>
<div class="line">}</div>
</div><!-- fragment --><p>All possible configurations will be generated combining each value in the range specified using <code>from</code>, <code>to</code>, <code>step</code> for each workload parameter. The benchmark for each configuration will be executed by Test Harness. The order of each combination is undefined.</p>
<p><b>IMPORTANT</b>: Because an external dataset provides inputs and outputs for a single benchmark configuration, if a benchmark description specifies an external dataset using the <code>dataset</code> field, then, the range of values for every workload parameter of said benchmark must contain a single element. Otherwise, an error is produced.</p>
<p><br  />
 Finally, backends may have extra workload parameters, beyond those required. Configuration files are expected to fulfill these as well. To know if and which extra parameters a backend has defined for a benchmark, users must consult the specific backend documentation. Exported configuration files may offer a hint at any extra parameters as well.</p>
<h1><a class="anchor" id="autotoc_md23"></a>
Default benchmark configuration</h1>
<p>The best starting point for creating a custom benchmark configuration file is to export the default configuration for a backend.</p>
<p>The exported file will contain the correct information regarding each benchmark ID and its workload parameters. Each benchmark will be preceded by a comment describing what the configuration represents (workload, category, category parameters, etc.).</p>
<p>Users may add, edit or remove benchmarks in this file as needed. Invalid configurations will be rejected by Test Harness when loading.</p>
<p>For example, if a backend exported configuration looks like below:</p>
<div class="fragment"><div class="line">default_min_test_time: 0</div>
<div class="line">default_sample_size: 0</div>
<div class="line">random_seed: 0</div>
<div class="line">initialization_data: ~</div>
<div class="line"> </div>
<div class="line">benchmark:</div>
<div class="line"> </div>
<div class="line"># Section &quot;description&quot; is for informational purposes only. It shows the</div>
<div class="line"># benchmark descriptor matching the benchmark ID. Changing contents of</div>
<div class="line"># &quot;description&quot; has no effect.</div>
<div class="line">  - ID: 3</div>
<div class="line">    description:</div>
<div class="line">      workload_id: 6</div>
<div class="line">      workload_name: Logistic Regression PolyD3</div>
<div class="line">      data_type: Float64</div>
<div class="line">      category: Offline</div>
<div class="line">      scheme: CKKS</div>
<div class="line">      security: 128 bits</div>
<div class="line">      cipher_flags: all_cipher</div>
<div class="line">      other: 0</div>
<div class="line">      notes: ~      </div>
<div class="line">    dataset: ~</div>
<div class="line">    default_min_test_time: 0</div>
<div class="line">    default_sample_size:</div>
<div class="line">      0: 0</div>
<div class="line">      1: 0</div>
<div class="line">      2: 100</div>
<div class="line">    params:</div>
<div class="line">      0:</div>
<div class="line">        name: n</div>
<div class="line">        type: UInt64</div>
<div class="line">        value:</div>
<div class="line">          from: 16</div>
<div class="line">          to: 16</div>
<div class="line">          step: 0</div>
</div><!-- fragment --><p>we know that for this backend, <code>ID</code> value of <code>3</code> will always represent what is contained in the description section: a "Logistic Regression PolyD3" workload, in the "Offline" category, with input and output data type "Float64", scheme "CKKS" with "128 bits" security, all operation parameters are encrypted, and the extra flags ("other") has a value of <code>0</code>. See <a class="el" href="logistic_regression.html">Logistic Regression Inference Workload</a> for full details on workload specification.</p>
<p>We can modify the parameters at will, as long as our new values are supported by the backend used to export this file.</p>
<p>We can add more benchmarks, as long as their IDs are one of the IDs in the original exported file, and the number of parameters and their types match the correct workload.</p>
<p>Note that adding benchmarks that exactly match parameters of other existing benchmarks will not cause an error. Test Harness will run duplicate benchmarks, but the results of the last run will overwrite the results of any previous runs of the duplicated benchmark.</p>
<h2><a class="anchor" id="autotoc_md24"></a>
Exporting default configuration</h2>
<p>The following command will make Test Harness query the specified backend and generate the file pointed by variable <code>$CONFIG_FILE_PATH</code> containing the benchmark configuration information to run the backend with default parameters, instead of running any benchmarks.</p>
<p>If the file already exists, it will be overwritten without notification.</p>
<div class="fragment"><div class="line">./test_harness --backend_lib_path $BACKEND_LIB --benchmark_config_file $CONFIG_FILE_PATH --dump_config</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md25"></a>
Running with a configuration file</h2>
<p>The command below will launch the Test Harness which will load the file pointed in <code>$CONFIG_FILE_PATH</code>, validate that the selection of benchmarks and parameters are supported by the backend, and then execute only those benchmarks specified in the configuration file.</p>
<div class="fragment"><div class="line">./test_harness --backend_lib_path $BACKEND_LIB --benchmark_config_file $CONFIG_FILE_PATH</div>
</div><!-- fragment --><p>See <a class="el" href="test_harness_usage_guide.html">Test Harness User Guide</a> for more information on using the Test Harness. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1 </li>
  </ul>
</div>
</body>
</html>
